# BPR: Bayesian Personalized Ranking from Implicit Feedback

La esencia de toda recomendación en muchos sistemas de recomendación, permiten tanto a los proveedores de productos y/o servicios, como a los propios consumidores aumentar las ventas o visitas, así como también hacer sentir al usuario que la personalización de sus compras o visitas resulte en una experiencia atractiva, que conlleva a la fidelización del usuario, entre otras cosas. En el paper los autores explican cómo realizar clasificaciones personalizadas a partir de la retroalimentación implícita, para ello utilizan dos modelos de recomendación el primero es la factorización de la matriz (MF), y el el segundo KNN adaptativo. Inicialmente se establece que si se tiene una probabilidad de A dado B eso es igual a la probabilidad de B, y multiplicada por la probabilidad de A, define la esencia del teorema de Bayer, donde se utiliza específicamente para hacer juegos de probabilidades, con el fin de realizar ranking personalizados usando el feedback implícitos que se han encontrado de los usuarios. 

Lo interesante acá es como los autores deciden optimizar técnicas para resolver esto a través de algoritmos usando el criterio de BPR-OPS, y como generar aprendizaje usando esté criterio. Para lo anterior definieron un dataset para el entrenamiento haciendo un ordenamiento de los ítems, con el fin de evitar que los datos no vistos pasen hacer necesariamente negativos, definiendo sí el ítem 1 es preferido pero el ítem 2 no lo es, se entenderá que 1>2, pero el usuario no ha visto ninguno de los dos ítems se considera que ambos 1 y 2 son iguales. Luego definen un nuevo paradigma de tuplas donde ya no es usuario-ítems (como en métodos KNN, por ejemplo), sino hacen una tupla de tres donde un usuario se relaciona a dos ítems, predeterminados, lo que refleja una comparación entre objetos, para no darle tanta negatividad a los ítems no vistos.

Ahora cabe preguntarse si esta será la mejor técnica para abordar el problema de la negatividad de los casos no vistos, o no clasificados. Al ser estocásticos toma datos al azar y eso no asegura que sea el más optimo al momento de entrenar a sus modelos. Por lo que hubiese sido interesante que hubiesen detallado la manera en que entrenaron su modelo, así como también la implementación de la solución.

